{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charurathour/Data-science-projects/blob/main/gemini_qa_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UbSgMSkMD46"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDw_qinLNuSy"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZSGD1HPN_F6"
      },
      "outputs": [],
      "source": [
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "GOOGLE_API_KEY=userdata.get('gemini')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "BYmDlHp6OS6e",
        "outputId": "5c4edf58-db06-4c81-bd4e-437d6e048d6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MfXMdgsOZAA"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-pro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS5pkkbtPQwP",
        "outputId": "dd7ef560-362e-4b9c-cd26-046fca0bf367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CX6PDXm2Ogug"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        num_pages = len(reader.pages)\n",
        "\n",
        "        text = ''\n",
        "        for page_num in range(num_pages):\n",
        "            page = reader.pages[page_num]\n",
        "            text += page.extract_text()\n",
        "\n",
        "        return text\n",
        "\n",
        "# Replace 'your_pdf_file.pdf' with the path to your PDF file\n",
        "pdf_text = extract_text_from_pdf('/content/Defensive Distillation is Not Robust to Adversarial Examples.pdf')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "Hd21pbHrPcRr",
        "outputId": "d39b9c0a-2db2-4ef3-8484-f7925eacc257"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Robustness Veriﬁcation of Tree-based Models\\nHongge Chen*,1Huan Zhang*,2Si Si3Yang Li3Duane Boning1Cho-Jui Hsieh2,3\\n1Department of EECS, MIT\\n2Department of Computer Science, UCLA\\n3Google Research\\nchenhg@mit.edu, huan@huan-zhang.com, sisidaisy@google.com\\nliyang@google.com, boning@mtl.mit.edu, chohsieh@cs.ucla.edu\\n*Hongge Chen and Huan Zhang contributed equally.\\nAbstract\\nWe study the robustness veriﬁcation problem for tree based models, including\\ndecision trees, random forests (RFs) and gradient boosted decision trees (GBDTs).\\nFormal robustness veriﬁcation of decision tree ensembles involves ﬁnding the\\nexact minimal adversarial perturbation or a guaranteed lower bound of it. Existing\\napproaches ﬁnd the minimal adversarial perturbation by a mixed integer linear\\nprogramming (MILP) problem, which takes exponential time so is impractical for\\nlarge ensembles. Although this veriﬁcation problem is NP-complete in general,\\nwe give a more precise complexity characterization. We show that there is a\\nsimple linear time algorithm for verifying a single tree, and for tree ensembles\\nthe veriﬁcation problem can be cast as a max-clique problem on a multi-partite\\ngraph with bounded boxicity. For low dimensional problems when boxicity can\\nbe viewed as constant, this reformulation leads to a polynomial time algorithm.\\nFor general problems, by exploiting the boxicity of the graph, we develop an\\nefﬁcient multi-level veriﬁcation algorithm that can give tight lower bounds on\\nrobustness of decision tree ensembles, while allowing iterative improvement and\\nany-time termination. On RF/GBDT models trained on 10 datasets, our algorithm is\\nhundreds of times faster than a previous approach that requires solving MILPs, and\\nis able to give tight robustness veriﬁcation bounds on large GBDTs with hundreds\\nof deep trees.\\n1 Introduction\\nRecent studies have demonstrated that neural network models are vulnerable to adversarial\\nperturbations—a small and human imperceptible input perturbation can easily change the predicted\\nlabel [ 37,17,6,15]. This has created serious security threats to many real applications so it becomes\\nimportant to formally verify the robustness of machine learning models. Usually, the robustness\\nveriﬁcation problem can be cast as ﬁnding the minimal adversarial perturbation to an input example\\nthat can change the predicted class label. A series of robustness veriﬁcation algorithms have been\\ndeveloped for neural network models [21, 38, 43, 42, 41, 47, 16, 35], where efﬁcient algorithms are\\nmostly based on convex relaxations of nonlinear activation functions of neural networks [32].\\nWe study the robustness veriﬁcation problem of tree-based models, including a single decision tree\\nand tree ensembles such as random forests (RFs) and gradient boosted decision trees (GBDTs). These\\nmodels have been widely used in practice [ 12,22,46] and recent studies have demonstrated that both\\nRFs and GBDTs are vulnerable to adversarial perturbations [ 20,13,9]. It is thus important to develop\\na formal robustness veriﬁcation algorithm for tree-based models. Robustness veriﬁcation requires\\ncomputing the minimal adversarial perturbation. [ 20] showed that computing minimal adversarial\\nperturbation for tree ensemble is NP-complete in general, and they proposed a Mixed-Integer Linear\\nProgramming (MILP) based approach to compute the minimal adversarial perturbation. Although\\n33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.arXiv:1906.03849v3  [cs.LG]  9 Dec 2019exact veriﬁcation is NP-hard, in order to have an efﬁcient veriﬁcation algorithm for real applications\\nwe seek to answer the following questions:\\n\\x0fDo we have polynomial time algorithms for exact veriﬁcation under some special circumstances?\\n\\x0fFor general tree ensemble models with a large number of trees, can we efﬁciently compute\\nmeaningful lower bounds on robustness while scaling to large tree ensembles?\\nIn this paper, we answer the above-mentioned questions afﬁrmatively by formulating the veriﬁcation\\nproblem of tree ensembles as a graph problem. First, we show that for a single decision tree,\\nrobustness veriﬁcation can be done exactly in linear time. Then we show that for an ensemble of K\\ntrees, the veriﬁcation problem is equivalent to ﬁnding the maximum cliques in a K-partite graph,\\nand the graph is in a special form with boxicity equal to the input feature dimension. Therefore,\\nfor low-dimensional problems, veriﬁcation can be done in polynomial time with maximum clique\\nsearching algorithms. Finally, for large-scale tree ensembles, we propose a multiscale veriﬁcation\\nalgorithm by exploiting the boxicity of the graph, which can give tight lower bounds on robustness.\\nFurthermore, it supports any-time termination: we can stop the algorithm at any time to obtain a\\nreasonable lower bound given a computation time constraint. Our proposed algorithm is efﬁcient and\\nis scalable to large tree ensemble models. For instance, on a large multi-class GBDT with 200 trees\\nrobustly trained (using [ 9]) on the MNIST dataset, we obtained 78% veriﬁed robustness accuracy on\\ntest set with maximum `1perturbation \\x0f= 0:2and the time used for verifying each test example is\\n12.6 seconds, whereas the MILP method uses around 10 min for each test example.\\n2 Background and Related Work\\nAdversarial Robustness For simplicity, we consider a multi-class classiﬁcation model f:Rd!\\nf1;:::;Cgwheredis the input dimension and Cis number of classes. For an input example x,\\nassuming that y0=f(x)is the correct label, the minimal adversarial perturbation is deﬁned by\\nr\\x03= min\\n\\x0ek\\x0ek1s.t.f(x+\\x0e)6=y0: (1)\\nNote that we focus on the `1norm measurement in this paper which is widely used in recent\\nstudies [ 25,43,5]. Exactly solving (1)is usually intractable. For example, if f(\\x01)is a neural network,\\n(1) is non-convex and [21] showed that solving (1) is NP-complete for ReLU networks.\\nAdversarial attacks are algorithms developed for ﬁnding a feasible solution \\x16\\x0eof(1), wherek\\x16\\x0ek1is\\nanupper bound ofr\\x03. Many algorithms have been proposed for attacking machine learning models\\n[17,23,6,25,10,11,18,3,13,28,24,45]. Most practical attacks cannot guarantee to reach the\\nminimal adversarial perturbation r\\x03due to the non-convexity of (1). Therefore, attacking algorithms\\ncannot provide any formal guarantee on model robustness [1, 40].\\nOn the other hand, robustness veriﬁcation algorithms are designed to ﬁnd the exact value or a\\nlower bound ofr\\x03. An exact veriﬁer needs to solve (1)to the global optimal, so typically we resort\\nto relaxed veriﬁers that give lower bounds. After a veriﬁcation algorithm ﬁnds a lower bound r, it\\nguarantees that no adversarial example exists within a radius rball aroundx. This is important for\\ndeploying machine learning algorithms to safety-critical applications such as autonomous vehicles or\\naircraft control systems [21, 19].\\nFor veriﬁcation, instead of solving (1)we can also solve the following decision problem of robust-\\nness veriﬁcation\\nDoes there exist an x02Ball(x;\\x0f)such thatf(x0)6=y0? (2)\\nIn our setting Ball(x;\\x0f) :=fx0:kx0\\x00xk1\\x14\\x0fg. If we can answer this decision (“yes”/“no”)\\nproblem, a binary search can give us the value of r\\x03, so the complexity of (2)is in the same order of (1).\\nFurthermore, solving (1)using an approximation algorithm (with answer “unknown” allowed) can\\nlead to a lower bound of r\\x03, which is useful for veriﬁcation. The decision version is also widely used\\nin the veriﬁcation community since “veriﬁed accuracy under \\x0fperturbation” is an important metric,\\nwhich is deﬁned as the portion of test samples that the answers to (2)are “no”. Veriﬁcation methods\\nfor neural networks have been studied extensively in the past few years [43, 44, 42, 47, 35, 16, 36].\\nAdversarial Robustness of Tree-based Models Unlike neural networks, decision-tree based mod-\\nels are non-continuous step functions, and thus existing neural network veriﬁcation techniques\\ncannot be directly applied. In [ 2], a single decision tree was veriﬁed to evaluate the robustness of\\nreinforcement learning policies. For tree ensembles, [ 20] showed that solving (1)for general tree\\n2ensemble models is NP-complete, so no polynomial time algorithm can compute r\\x03for arbitrary trees\\nunless P=NP. A Mixed Integer Linear Programming (MILP) algorithm was thus proposed in [ 20] to\\ncompute (1)in exponential time. Recently, [ 14] and [ 33] verify the robustness of tree ensembles using\\nan SMT solver, which is also NP-complete in its natural formulation. Additionally, an approximate\\nbound for tree ensembles was proposed recently in [ 39] by directly combining the bounds of each\\ntree together, which can be seen as a special case of our proposed method.\\nOn the other hand, robustness can be empirically evaluated through adversarial attacks [ 27]. Some\\nhard-label attacking algorithms for neural networks, including the boundary attack [ 3] and OPT-\\nattack [ 13], can be applied to tree based models since they only require function evaluation of the\\nnon-smooth (hard-label) decision function f(\\x01). These attacks computes an upper bound of r\\x03. In\\ncontrast, our work focuses on efﬁciently computing a tight lower bound of r\\x03for ensemble trees.\\n3 Proposed Algorithm\\nThe exact veriﬁcation problem of tree ensemble is NP-complete by its nature, and here we propose a\\nseries of efﬁcient veriﬁcation algorithms for real applications. First, we will introduce a linear time\\nalgorithm for exactly computing the minimal adversarial distortion r\\x03for verifying a single decision\\ntree. For an ensemble of trees, we cast the veriﬁcation problem into a max-clique searching problem\\nin K-partite graphs. For large-scale tree ensembles, we then propose an efﬁcient multi-level algorithm\\nfor verifying an ensemble of decision trees.\\n3.1 Exactly Verifying a Single Tree in Linear Time\\nAlthough computing r\\x03for a tree ensemble is NP-complete [ 20], we show that a linear time\\nalgorithm exists for ﬁnding the minimum adversarial perturbation and computing r\\x03for a single\\ndecision tree. We assume the decision tree has nnodes and the root node is indexed as 0. For a\\ngiven example x= [x1;:::;xd]withdfeatures, starting from the root, xtraverses the decision tree\\nmodel until reaching a leaf node. Each internal node, say node i, has two children and a univariate\\nfeature-threshold pair (ti;\\x11i)to determine the traversal direction— xwill be passed to the left child if\\nxti\\x14\\x11iand to the right child otherwise. Each leaf node has a value vicorresponding to the predicted\\nclass label for a classiﬁcation tree, or a real value for a regression tree.\\nConceptually, the main idea of our single tree veriﬁcation algorithm is to compute a d-dimensional\\nbox for each leaf node such that any example in this box will fall into this leaf. Mathematically, the\\nnodei’s box is deﬁned as the Cartesian product Bi= (li\\n1;ri\\n1]\\x02\\x01\\x01\\x01\\x02 (li\\nd;ri\\nd]ofdintervals on the\\nreal line. By deﬁnition, the root node has box [\\x001;1]\\x02\\x01\\x01\\x01\\x02 [\\x001;1]and given the box of an\\ninternal node i, its children’s boxes can be obtained by changing only one interval of the box based on\\nthe split condition (ti;\\x11i). More speciﬁcally, if p;qare nodei’s left and right child node respectively,\\nthen we set their boxes Bp= (lp\\n1;rp\\n1]\\x02\\x01\\x01\\x01\\x02 (lp\\nd;rp\\nd]andBq= (lq\\n1;rq\\n1]\\x02\\x01\\x01\\x01\\x02 (lq\\nd;rq\\nd]by setting\\n(lp\\nt;rp\\nt] =\\x1a(li\\nt;ri\\nt] ift6=ti\\n(li\\nt;minfri\\nt;\\x11ig]ift=ti;(lq\\nt;rq\\nt] =\\x1a(li\\nt;ri\\nt] ift6=ti\\n(maxfli\\nt;\\x11ig;ri\\nt]ift=ti:(3)\\nAfter computing the boxes for internal nodes, we can also obtain the boxes for leaf nodes using (3).\\nTherefore computing the boxes for all the leaf nodes of a decision tree can be done by a depth-ﬁrst\\nsearch traversal of the tree with time complexity O(nd).\\nWith the boxes computed for each leaf node, the minimum perturbation required to change xto go to\\na leaf nodeican be written as a vector \\x0f(x;Bi)2Rddeﬁned as\\n\\x0f(x;Bi)t:=8\\n<\\n:0 ifxt2(li\\nt;ri\\nt]\\nxt\\x00ri\\ntifxt>ri\\nt\\nli\\nt\\x00xtifxt\\x14li\\nt:(4)\\nThen the minimal distortion can be computed as r\\x03= mini:vi6=y0k\\x0f(x;Bi)k1, wherey0is the\\noriginal label of x, andviis the label for leaf node i. To ﬁndr\\x03, we checkBifor all leaves and\\nchoose the smallest perturbation. This is a linear-time algorithm for exactly verifying the robustness\\nof a single decision tree. In fact, this O(nd)time algorithm is used to illustrate the concept of “boxes”\\nthat will be used later on for the tree ensemble case. If our ﬁnal goal is to verify a single tree, we\\ncan have a more efﬁcient algorithm by combining the distance computation (4)in the tree traversal\\nprocedure, and the resulting algorithm will take only O(n)time. This algorithm is presented as\\nAlgorithm 3 in the Appendix.\\n33.2 Verifying Tree Ensembles by Max-clique Enumeration\\nNow we discuss the robustness veriﬁcation for tree ensembles. Assuming the tree ensemble has K\\ndecision trees, we use S(k)to denote the set of leaf nodes of tree kandm(k)(x)to denote the function\\nthat maps the input example xto the leaf node of tree kaccording to its traversal rule. Given an input\\nexamplex, the tree ensemble will pass xto each of these Ktrees independently and xreachesK\\nleaf nodesi(k)=m(k)(x)for allk= 1;:::;K . Each leaf node will assign a prediction value vi(k).\\nFor simplicity we start with the binary classiﬁcation case, with x’s original label being y0=\\x001and\\nwe want to turn it into +1. For binary classiﬁcation the prediction of the tree ensemble is computed\\nbysign(P\\nkvi(k)), which covers both GBDTs and random forests, two widely used tree ensemble\\nmodels. Assume xhas a labely0=\\x001, which means sign(P\\nkvi(k))<0forx, and our task is to\\nverify if the sign of the summation can be ﬂipped within Ball (x;\\x0f).\\nWe consider the decision problem of robustness veriﬁcation (2). A naive analysis will need to check\\nall the points in Ball(x;\\x0f)which is uncountably inﬁnite. To reduce the search space to ﬁnite, we\\nstart by deﬁning some notation: let C=f(i(1);:::;i(K))ji(k)2S(k);8k= 1;:::;Lgto be all the\\npossible tuples of leaf nodes and let C(x) = [m(1)(x);:::;m(K)(x)]be the function that maps xto\\nthe corresponding leaf nodes. Therefore, a tuple C2Cdirectly determines the model predictionPvC:=P\\nkvi(k). Now we deﬁne a valid tuple for robustness veriﬁcation:\\nDeﬁnition 1. A tupleC= (i(1);:::;i(K))is valid if and only if there exists an x02Ball(x;\\x0f)such\\nthatC=C(x0).\\nThe decision problem of robustness veriﬁcation (2) can then be written as:\\nDoes there exist a valid tuple Csuch thatX\\nvC>0?\\nNext, we show how to model the set of valid tuples. We have two observations. First, if a tuple\\ncontains any node iwithinfx02Bifkx\\x00x0k1g>\\x0f, then it will be invalid. Second, there exists an x\\nsuch thatC=C(x)if and only if Bi(1)\\\\\\x01\\x01\\x01\\\\Bi(K)6=;, or equivalently:\\n(li(1)\\nt;ri(1)\\nt]\\\\\\x01\\x01\\x01\\\\ (li(K)\\nt;ri(K)\\nt]6=;;8t= 1;:::;d:\\nWe show that the set of valid tuples can be represented as cliques in a graph G= (V;E), where\\nV:=fijBi\\\\Ball(x;\\x0f)6=;gandE:=f(i;j)jBi\\\\Bj6=;g. In this graph, nodes are the leaves of\\nall trees and we remove every leaf that has empty intersection with Ball(x;\\x0f). There is an edge (i;j)\\nbetween node iandjif and only if their boxes intersect. The graph will then be a K-partite graph\\nsince there cannot be any edge between nodes from the same tree, and thus maximum cliques in this\\ngraph will have Knodes. We deﬁne each part of the K-partite graph as Vk. Here a “part” means a\\ndisjoint and independent set in the K-partite graph. The following lemma shows that intersections of\\nboxes have very nice properties:\\nLemma 1. For boxesB1;:::;BK, ifBi\\\\Bj6=;for alli;j2[K], let\\x16B=B1\\\\B2\\\\\\x01\\x01\\x01\\\\BK\\nbe their intersection. Then \\x16Bwill also be a box and \\x16B6=;.\\nThe proof can be found in the Appendix. Based on the above lemma, each K-clique (fully connected\\nsubgraph with Knodes) inGcan be viewed as a set of leaf nodes that has nonempty intersection\\nwith each other and also has nonempty intersection with Ball(x;\\x0f), so the intersection of those K\\nboxes and Ball(x;\\x0f)will be a nonempty box, which implies each K-clique corresponds to a valid\\ntuple of leaf nodes:\\nLemma 2. A tupleC= (i(1);:::;i(K))is valid if and only if nodes i(1);:::;i(K)form aK-clique\\n(maximum clique) in graph Gconstructed above.\\nTherefore the robustness veriﬁcation problem can be formulated as\\nIs there a maximum clique CinGsuch thatX\\nvC>0? (5)\\nThis reformulation indicates that the tree ensemble veriﬁcation problem can be solved by an efﬁcient\\nmaximum clique enumeration algorithm. Some standard maximum clique searching algorithms can\\nbe applied here to perform veriﬁcation:\\n\\x0fFindingK-cliques inK-partite graphs: Any algorithm for ﬁnding all the maximum cliques\\ninGcan be used. The classic B-K backtracking algorithm [ 4] takesO(3m\\n3)time to ﬁnd all\\n4the maximum cliques where mis the number of nodes in G. Furthermore, since our graph is a\\nK-partite graph, we can apply some specialized algorithms designed for ﬁnding all the K-cliques\\ninK-partite graphs [26, 29, 34].\\n\\x0fPolynomial time algorithms exist for low-dimensional problems: Another important property\\nfor graphGis that each node in Gis ad-dimensional box and each edge indicates the intersection\\nof two boxes. This implies our graph Gis with “boxicity d” (see [ 7] for detail). [ 7] proved that\\nthe number of maximum cliques will only be O((2m)d)and it is able to ﬁnd the maximum weight\\nclique inO((2m)d)time. Therefore, for problems with a very small d, the time complexity for\\nveriﬁcation is actually polynomial.\\nTherefore we can exactly solve the tree ensemble veriﬁcation problem using algorithms for maximum\\ncliques searching in K-partite graph, and its time complexity is found to be as follows:\\nTheorem 1. Exactly verifying the robustness of a K-tree ensemble with at most nleaves per tree\\nandddimensional features takes minfO(nK);O((2Kn)d)gtime.\\nThis is a direct consequence of the fact that the number of K-cliques in a K-partite graph with n\\nvertices per part is bounded by O(nK), and number of maximum cliques in a graph with a total\\nofmnodes with boxicity disO((2m)d). For a general graph, since Kanddcan be inO(n)and\\nO(m)[31], it can still be exponential. But the theorem gives a more precise characterization for the\\ncomplexity of the veriﬁcation problem for tree ensembles. Based on the nice properties of maximum\\ncliques searching problem, we propose a simple and elegant algorithm that enumerates all K-cliques\\non aK-partite graph with a known boxicity din Algorithm 1, and we can use this algorithm for tree\\nensemble veriﬁcation when the number of trees or the dimension of features is small.\\nFor aK-partite graph G, we deﬁne the set ~V:=fV1;V2;\\x01\\x01\\x01;VKgwhich is a set of independent\\nsets (“parts”) in G. The algorithm ﬁrst looks at any ﬁrst two parts V1andV2of the graph and\\nenumerates all 2-cliques in O(jV1jjV2j)time. Then, each 2-clique found is converted into a “pseudo\\nnode” (this is possible due to Lemma 1), and all 2-cliques form a new part V0\\n2of the graph. Then\\nwe replaceV1andV2withV0\\n2, and continue to enumerate all 2-cliques between V0\\n2andV3to form\\nV0\\n3. A 2-clique between V0\\n2andV3represents a 3-clique in V1,V2andV3due to boxicity. Note that\\nenumerating all 3-cliques in a general 3-partite graph takes O(jV1jjV2jjV3j)time; thanks to boxicity,\\nour algorithm takes O(jV0\\n2jjV3j)time which equals to O(jV1jjV2jjV3j)only whenV1andV2form a\\ncomplete bipartite graph, which is unlikely in common cases. This process continues recursively\\nuntil we process all Kparts and have only V0\\nKleft, where each vertex in V0\\nKrepresents a K-clique in\\nthe original graph. After obtaining all K-cliques, we can verify their prediction values to compute a\\nveriﬁcation bound.\\nAlgorithm 1: Enumerating all K-cliques on a K-partite graph with a known boxicity d\\ninput :V1; V2; ;:::; VKare theKindependent sets (“parts”) of a K-partite graph\\n1fork 1;2;3; :::; K do\\n2Uk f(Ai; Bi(k))ji(k)2Vk; Ai=fi(k)gg;\\n/*Uis a set of tuples (A; B), which stores a set of cliques and their corresponding boxes. Ais\\nthe set of nodes in one clique and Bis the corresponding box of this clique. Initially, each\\nnode in Vkforms a 1-clique itself. */\\n3end\\n4CliqueEnumerate( U1; U2; ;:::; UK);\\n5Function CliqueEnumerate( U1; U2; ;:::; UK)\\n6 ^Uold U1;\\n7 fork 2;3; :::; K do\\n8 ^Unew ;;\\n9 for(^A;^B)2^Uolddo\\n10 for(A; B )2Ukdo\\n11 ifB\\\\^B6=;then\\n/*Ak-clique is found; add it as a pseudo node with the intersection of two boxes. */\\n12 ^Unew ^Unew[f(A[^A; B\\\\^B)g;\\n13 end\\n14 end\\n15 ^Uold ^Unew;\\n16 end\\n17 return ^Unew;\\n18end\\n5Tree (1) \\n1 2 3Tree (2) \\n5 6 7Tree (3) \\n9 10 11Tree (4) \\n13 16 4 8 12 14 15 Leaf nodes \\n3, 6 4, 8 12, 14 12, 15 Merge (1) and (2) Merge (3) and (4) \\nMerge (1) (2) and (3) (4) \\n3, 6, 12, 14 4, 8, 12, 15 Final (exact) solution Run single-level algorithm \\nto get level 1 bound \\nRun single-level algorithm \\nto get level 2 bound Figure 1: The proposed multi-level veriﬁcation algorithm. Lines between leaf node i on tree t1and\\nleaf nodejont2indicate that their `1feature boxes intersect (i.e., there exists an input such that\\ntree 1 predicts viand tree 2 predicts vj).\\n3.3 An Efﬁcient Multi-level Algorithm for Verifying the Robustness of a Tree Ensemble\\nPractical tree ensembles usually have tens or hundreds of trees with large feature dimensions, so\\nAlgorithm 1 will take exponential time and will be too slow. We thus develop an efﬁcient multi-level\\nalgorithm for computing veriﬁcation bounds by further exploiting the boxicity of the graph.\\nFigure 1 illustrates the graph and how our multilevel algorithm runs. There are four trees and each\\ntree has four leaf nodes. A node is colored if it has nonempty intersection with Ball(x;\\x0f); uncolored\\nnodes are discarded. To answer question (5), we need to compute the maximumPvCamong all\\nK-cliques, denoted by v\\x03. As mentioned before, for robustness veriﬁcation we only need to compute\\nan upper bound of v\\x03in order to get a lower bound of minimal adversarial perturbation. In the\\nfollowing, we will ﬁrst discuss algorithms for computing an upper bound at the top level, and then\\nshow how our multi-scale algorithm iteratively reﬁnes this bound until reaching the exact solution v\\x03.\\nBounds for a single level. To compute an upper bound of v\\x03, a naive approach is to assume that\\nthe graph is fully connected between independent sets (fully connected K-partite graph) and in this\\ncase the maximum sum of node values is the sum of the maximum value of each independent set:\\nXj~Vj\\nk=1maxi2Vkvi\\x15v\\x03: (6)\\nHere we abuse the notation viby assuming that each node iinVkhas been assigned a “pseudo\\nprediction value”, which will be used in the multi-level setting. In the simplest case, each independent\\nset represents a single tree, Vk=S(k)andviis the prediction of a leaf. One can easily show this is\\nan upper bound of v\\x03since anyK-clique in the graph is still considered when we add more edges to\\nthe graph, and eventually it becomes a fully connected K-partite graph.\\nAnother slightly better approach is to exploit the edge information but only between tree tandt+ 1.\\nIf we search over all the length- Kpaths [i(1);:::;i(K)]from the ﬁrst to the last part and deﬁne the\\nvalue of a path to beP\\nkvi(k), then the maximum valued path will be a upper bound of v\\x03. This can\\nbe computed in linear time using dynamic programming. We scan nodes from tree 1to treeK, and\\nfor each node we store a value diwhich is the maximum value of paths from tree 1to this node. At\\ntreekand nodei, thedivalue can be computed by\\ndi=vi+ max\\nj:j2Vk\\x001and(j;i)2Edj: (7)\\nThen we take the max dvalue in the last tree. It produces an upper bound of v\\x03, since the maximum\\nvalued path found by dynamic programming is not necessarily a K-clique. Again Vk\\x001=S(k\\x001)in\\nthe ﬁrst level but it will be generalized below.\\nMergingTindependent sets To reﬁne the relatively loose single-level bound, we partition the\\ngraph intoK=T subgraphs, each with Tindependent sets. Within each subgraph, we ﬁnd all the\\nT-cliques and use a new “pseudo node” to represent each T-clique.T-cliques in a subgraph can be\\nenumerated efﬁciently if we choose Tto be a relatively small number (e.g., 2or3in the experiments).\\nNow we exploit the boxicity property to form a new graph among these T-cliques (illustrated as the\\nsecond level nodes in Figure 1). By Lemma 1, we know that the intersection of Tboxes will still be\\n6a box, so each T-clique is still a box and can be represented as a pseudo node in the level-2 graph.\\nAlso because each pseudo node is still a box, we can easily form edges between pseudo nodes to\\nindicate the nonempty overlapping between them and this will be a (K=T )-partite boxicity graph\\nsince no edge can be formed for the cliques within the same subgraph. Thus we get the level-2 graph.\\nWith the level-2 graph, we can again run the single level algorithm to compute a upper bound on v\\x03\\nto get a lower bound of r\\x03in(1), but different from the level-1 graph, now we already considered all\\nthe within-subgraph edges so the bounds we get will be tighter.\\nThe overall multi-level framework We can run the algorithm level by level until merging all the\\nsubgraphs into one, and in the ﬁnal level the pseudo nodes will correspond to the K-cliques in the\\noriginal graph, and the maximum value will be exactly v\\x03. Therefore, our algorithm can be viewed as\\nan anytime algorithm that reﬁnes the upper bound level-by-level until reaching the maximum value.\\nAlthough getting to the ﬁnal level still requires exponential time, in practice we can stop at any level\\n(denoted asL) and get a reasonable bound. In experiments, we will show that by merging few trees\\nwe already get a bound very close to the ﬁnal solution. Algorithm 2 gives the complete procedure.\\nAlgorithm 2: Multi-level veriﬁcation framework\\ninput : The set of leaf nodes of each tree, S(1); S(2); ;:::; S(K); maximum number of independent sets in a subgraph\\n(denoted asT); maximum number of levels (denoted as L),L\\x14dlogT(K)e;\\n1fork 1;2; :::; K do\\n2U(0)\\nk f(Ai; Bi(k))ji(k)2S(k); Ai=fi(k)gg;\\n/*Uis defined the same as in Algorithm 1. At level 0, each Vkforms a 1-clique by itself. */\\n3end\\n4forl 1;2; :::; L do\\n/*Enumerate all cliques in each subgraph at this level. Total dK=Tlesubgraphs. */\\n5 fork 1;2; :::;dK=Tledo\\n6U(l)\\nk CliqueEnumerate( U(l\\x001)\\n(k\\x001)T+1; U(l\\x001)\\n(k\\x001)T+2; :::; U(l\\x001)\\nkT);\\n7 end\\n8end\\n9fork 1;2; :::;dK=TLedo\\n/*Define an independent set V0\\nkfor each U(L)\\nk. In each V0\\nk, we create “pseudo nodes” which combines\\nmultiple nodes from lower levels, and assign “pseudo prediction values” to them. */\\n10V0\\nk fA\\x0c\\x0c(A;B)2U(L)\\nkg; /*V0\\nkis a set of sets; each element in V0\\nkrepresents a clique. */\\n/*Construct the “pseudo prediction value” for each element in V0\\nkby summing up all prediction\\nvalues in the corresponding clique. */\\n11 For allA2V0\\nk,vA P\\ni2Avi\\n12end\\n13\\x16v an upper bound of v\\x03using (6) or (7), given ~V=fV0\\n1;\\x01\\x01\\x01;V0\\ndK=TLeg;\\n/*IfdK=TLe= 1, only 1 independent set left and each pseudo node represents a K-clique; (6)or(7)\\nwill have a trivial solution where v\\x03is the maximum vAinU(L)\\n1. */\\nHandling multi-class tree ensembles For a multiclass classiﬁcation problem, say a C-class classi-\\nﬁcation problem, Cgroups of tree ensembles (each with Ktrees) are built for the classiﬁcation task;\\nfor thek-th tree in group c, prediction outcome is denoted as i(k;c)=m(k;c)(x)wherem(k;c)(x)is\\nthe function that maps the input example xto a leaf node of tree kin groupc. The ﬁnal prediction is\\ngiven by argmaxcP\\nkvi(k;c). Given an input example xwith ground-truth class cand an attack target\\nclassc0, we extract 2Ktrees for class cand classc0, and ﬂip the sign of all prediction values for trees\\nin groupc0, such that initiallyP\\ntvi(t;c)+P\\ntvi(t;c0)<0for a correctly classiﬁed example. Then,\\nwe are back to the binary classiﬁcation case with 2Ktrees, and we can still apply our multi-level\\nframework to obtain a lower bound r(c;c0)ofr\\x03\\n(c;c0)for this target attack pair (c;c0). Robustness of an\\nuntargeted attack can be evaluated by taking r= minc06=cr(c;c0).\\n3.4 Veriﬁcation Problems Beyond Ordinary Robustness\\nThe above discussions focus on the decision problem of `1robustness veriﬁcation (2). In fact, our\\napproach works for a more general veriﬁcation problem for anyd-dimensional box B:\\nIs there any x02Bsuch thatf(x0)6=y0? (8)\\nIn typical robustness veriﬁcation settings, Bis deﬁned to be Ball(x;\\x0f)but in fact we can allow any\\nboxes in our algorithm. For a general B, Lemma 1 still holds so all of our algorithms and analysis\\ncan go through. The only change is to compute the intersection between Band each box of leaf\\nnode at the ﬁrst level in Figure 1 and eliminate nodes that have an empty intersection with B. So\\n7robustness veriﬁcation is just a special case where we remove all the nodes with empty intersection\\nwith Ball(x;\\x0f). For example, we can identify a set of unimportant variables, where any individual\\nfeature change in this set cannot alter the prediction for a given sample x. For each feature i, we\\ncan choose BasBi= [\\x001;1](or the the entire input domain, like [0;1]for image data) and\\nBj6=i=fxjgotherwise. If the model is robust to such a single-feature perturbation, then this feature\\nis added to the unimportant set. Similarly, we can get a set of anchor features (similar to [ 30]) such\\nthat once a set of features are ﬁxed, any perturbation outside the set cannot change the prediction.\\n4 Experiments\\nWe evaluate our proposed method for robustness veriﬁcation of tree ensembles on two tasks: binary\\nand multiclass classiﬁcation on 9 public datasets including both small and large scale datasets. Our\\ncode (XGBoost compatible) is available at https://github.com/chenhongge/treeVeriﬁcation. We run\\nour experiments on Intel Xeon Platinum 8160 CPUs. The datasets other than MNIST and Fashion-\\nMNIST are from LIBSVM [ 8]. The statistics of the data sets are shown in Appendix A. As we\\ndeﬁned in Section 2, r\\x03is the radius of minimum adversarial perturbation that reﬂects true model\\nrobustness, but is hard to obtain; our method ﬁnds rthat is a lower bound of r\\x03, which guarantees\\nthatno adversarial example exists within radius r. A high quality lower bound rshould be close to\\nr\\x03. We include the following algorithms in our comparisons:\\n\\x0fCheng’s attack [ 13] provides results on adversarial attacks on these models, which gives an upper\\nbound of the model robustness r\\x03. We denote it as randr\\x15r\\x03.\\n\\x0fMILP: an MILP (Mixed Integer Linear Programming) based method [ 20] gives the exact r\\x03. It can\\nbe very slow when the number of trees or dimension of the features increases.\\n\\x0fLP relaxation: a Linear Programming (LP) relaxed MILP formulation by directly changing\\nall binary variables to continuous ones. Since the binary constraints are removed, solving the\\nminimization of MILP gives a lower bound of robustness, rLP, serving as a baseline method.\\n\\x0fOur proposed multi-level veriﬁcation framework in Section 3.3 (with pseudo code as Algorithm 2 in\\nthe appendix). We are targeting to compute robustness interval rourfor tree ensemble veriﬁcation.\\nIn Tables 1 and 2 we show empirical comparisons on 9 datasets. We consider `1robustness, and\\nnormalize our datasets to [0;1]such that perturbations on different datasets are comparable. We\\nuse(6)to obtain single layer bounds. Results using dynamic programming in (7)are provided in\\nAppendix B. We include both standard (naturally trained) GBDT models (Table 1) and robust GBDT\\nmodels [ 9] (Table 2). The robust GBDTs were trained by considering model performance under the\\nworst-case perturbation, which leads to a max-min saddle point problem when ﬁnding the optimal\\nsplit at each node [ 9]. All GBDTs are trained using the XGBoost framework [ 12]. The number of\\ntrees in GBDTs and parameters used in training GBDTs for different datasets are shown in Table 3 in\\nthe appendix. Because we solve the decision problem of robustness veriﬁcation, we use a 10-step\\nbinary search to ﬁnd the largest rin all experiments, and the reported time is the total time including\\nall binary search trials. We present the average of rorr\\x03over 500 examples. The MILP based\\nmethod from [ 20] is an accurate but very slow method; the results marked with an asterisk (“*”) in\\nthe table have very long running time and thus we only evaluate 50 examples instead of 500.\\nDatasetCheng’s attack [13] MILP [20] LP relaxation Ours (without DP) Ours vs. MILP\\navg.ravg. time avg.r\\x03avg. time avg.rLPavg. timeTLavg.rouravg. timerour=r\\x03speedup\\nbreast-cancer .221 2.18s .210 .012s .064 .009s 21 .208 .001s .99 12X\\ncovtype .058 4.76s:028?355?s:005?154?s23 .022 3.39s .79 105X\\ndiabetes .064 1.70s .049 .061s .015 .026s 32 .042 .018s .86 3.4X\\nFashion-MNIST .048 12.2s:014?1150?s:003?898?s21 .012 11.8s .86 97X\\nHIGGS .015 3.80s:0028?68?min:00035?50?min 41.0022 1.29s .79 3163X\\nijcnn1 .047 2.72s .030 4.64s .008 2.67s 22 .026 .101s .87 4.6X\\nMNIST .070 11.1s:011?367?s:003?332?s22 .011 5.14s 1.00 71X\\nwebspam .027 5.83s .00076 47.2s .0002 39.7s 21.0005 .404s .66 117X\\nMNIST 2 vs. 6 .152 12.0s .057 23.0s .016 11.6s 41 .046 .585s .81 39X\\nTable 1: Average `1distortion over 500 examples and average veriﬁcation time per example for three\\nveriﬁcation methods. Here we evaluate the bounds for standard (natural) GBDT models . Results\\nmarked with a start (“ ?”) are the averages of 50 examples due to long running time. Tis the number\\nof independent sets and Lis the number of levels in searching cliques used in our algorithm. A ratio\\nrour=r\\x03close to 1 indicates better lower bound quality. Dynamic programming in (7)is not applied.\\nResults using dynamic programming are provided in Appendix B.\\nFrom Tables 1 and 2 we can see that our method gives a tight lower bound rcompared to r\\x03from\\nMILP, while achieving up to \\x183000 X speedup on large models. The running time of the baseline\\n8DatasetCheng’s attack [13] MILP [20] LP relaxation Ours (without DP) Ours vs. MILP\\navg.ravg. time avg.r\\x03avg. time avg.rLPavg. timeTLavg.rouravg. timerour=r\\x03speedup\\nbreast-cancer .404 1.96s .400 .009s .078 .008s 21 .399 .001s 1.00 9X\\ncovtype .079 .481s:046?305?s:0053?159?s23 .032 4.84s .70 63X\\ndiabetes .137 1.52s .112 .034s .035 .013s 32 .109 .006s .97 5.7X\\nFashion-MNIST .153 13.9s:091?41?min:009?34?min 21 .071 18.0s .78 137X\\nHIGGS .023 3.58s:0084?59?min:00031?54?min 41.0063 1.41s .75 2511X\\nijcnn1 .054 2.63s .036 2.52s .009 1.26s 22 .032 0.58s .89 4.3X\\nMNIST .367 1.41s:264?615?s:019?515?s22 .253 12.6s .96 49X\\nwebspam .048 4.97s .015 83.7s .0024 60.4s 21 .011 .345s .73 243X\\nMNIST 2 vs. 6 .397 17.2s .313 91.5s .039 40.0s 41 .308 3.68s .98 25X\\nTable 2: Veriﬁcation bounds and running time for robustly trained GBDT models introduced in [ 9].\\nThe settings for each method are similar to the settings in Table 1.\\nLP relaxation, however, is on the same order of magnitude as the MILP method, but the results are\\nmuch worse, with rLP\\x1cr\\x03. Figure 2 shows how the tightness of our robustness veriﬁcation lower\\nbounds changes with different size of clique per level ( T) and different number of levels ( L). We\\ntest on a 20-tree standard GBDT model on the diabetes dataset. We also show the exact bound r\\x03\\nby the MILP method. Our veriﬁcation bound converges to the MILP bound as more levels of clique\\nenumerations are used. Also, when we use larger cliques in each level, the bound becomes tighter.\\nTo show the scalability of our method, we vary the number of trees in GBDTs and compare per\\nexample running time with the MILP method on ijcnn1 dataset in Figure 3. We see that our multi-level\\nmethod spends much less time on each example compared to the MILP method and our running time\\ngrows slower than MILP when the number of trees increases.\\n1\\n 2\\n 3\\n 4\\n 5\\n 6\\nNumber of Levels\\n0.00\\n0.01\\n0.02\\n0.03\\n0.04\\n0.05Robustness Bound\\nStandard GBDT (diabetes)\\n2-clique\\n3-clique\\n4-clique\\nMILP\\n1\\n 2\\n 3\\n 4\\n 5\\n 6\\nNumber of Levels\\n0.00\\n0.01\\n0.02\\n0.03\\n0.04\\n0.05Robustness Bound\\nRobust GBDT (ijcnn1)\\n2-clique\\n3-clique\\n4-clique\\nMILP\\nFigure 2: Robustness bounds obtained with different param-\\neters (T=f2;3;4g,L=f1;\\x01\\x01\\x01;6g) on a 20-tree standard\\nGBDT model trained on diabetes dataset (left) and a 20-tree\\nrobust GBDT model trained on ijcnn1 dataset (right). rour\\nconverges to r\\x03asLincreases.\\n20\\n 40\\n 60\\n 80\\n 100\\nNumber of Trees\\n10−4\\n10−3\\n10−2\\n10−1\\n100\\n101\\nRunning Time Per Example (s)\\nRobust GBDT (ijcnn1)\\n2-clique, 1-level\\n2-clique, 2-level\\n3-clique, 1-level\\nMILPFigure 3: Running time of MILP and\\nour method on robust GBDTs with dif-\\nferent number of trees (ijcnn1 dataset).\\nIn Section 3.4, we showed that our algorithm works for more general veriﬁcation problems such\\nas identifying unimportant features, where any changes on one of those features alone cannot alter\\nthe prediction. We use MNIST to demonstrate pixel importance, where we perturb each pixel\\nindividually by\\x06\\x0fwhile keeping other pixels unchanged, and obtain the largest \\x0fsuch that prediction\\nis unchanged. In Figure 4, yellow pixels cannot change prediction for any perturbation and a darker\\npixel represents a smaller lower bound rof perturbation to change the model output using that\\npixel. The standard naturally trained model has some very dark pixels compared to the robust model.\\nDiscussion on the connection between this score and other feature importance scores is in Section C.\\nStandard DT\\n Robust DT\\n0.00.51.0\\nStandard DT\\n Robust DT\\n0.00.51.0\\nStandard DT\\n Robust DT\\n0.00.51.0\\nFigure 4: MNIST pixel importance. For each 3-image group, left: digit image; middle: results on\\nstandard DT model; right: results on robust DT model. Changing one of any yellow pixels ( r= 1:0)\\nto any valid values between 0 and 1 cannot alter model prediction; pixels in darker colors (smaller r)\\ntend to affect model prediction more than pixels in lighter colors (larger r).\\nAcknowledgement. Chen and Boning acknowledge the support of SenseTime. Hsieh acknowledges\\nthe support of NSF IIS-1719097 and Intel faculty award.\\n9References\\n[1]Anish Athalye, Nicholas Carlini, and David Wagner. Obfuscated gradients give a false sense of security:\\nCircumventing defenses to adversarial examples. In ICML , 2018.\\n[2]Osbert Bastani, Yewen Pu, and Armando Solar-Lezama. Veriﬁable reinforcement learning via policy\\nextraction. In Advances in Neural Information Processing Systems , pages 2494–2504, 2018.\\n[3]Wieland Brendel, Jonas Rauber, and Matthias Bethge. Decision-based adversarial attacks: Reliable attacks\\nagainst black-box machine learning models. In ICLR , 2018.\\n[4]Coen Bron and Joep Kerbosch. Algorithm 457: ﬁnding all cliques of an undirected graph. Communications\\nof the ACM , 16(9):575–577, 1973.\\n[5]Rudy R Bunel, Ilker Turkaslan, Philip Torr, Pushmeet Kohli, and Pawan K Mudigonda. A uniﬁed view\\nof piecewise linear neural network veriﬁcation. In Advances in Neural Information Processing Systems ,\\npages 4790–4799, 2018.\\n[6]Nicholas Carlini and David Wagner. Towards evaluating the robustness of neural networks. In 2017 IEEE\\nSymposium on Security and Privacy (SP) , pages 39–57. IEEE, 2017.\\n[7]L Sunil Chandran, Mathew C Francis, and Naveen Sivadasan. Geometric representation of graphs in low\\ndimension using axis parallel boxes. Algorithmica , 56(2):129, 2010.\\n[8]Chih-Chung Chang and Chih-Jen Lin. LIBSVM: A library for support vector machines. ACM Transactions\\non Intelligent Systems and Technology , 2:27:1–27:27, 2011. Software available at http://www.csie.ntu.edu.\\ntw/~cjlin/libsvm.\\n[9]Hongge Chen, Huan Zhang, Duane Boning, and Cho-Jui Hsieh. Robust decision trees against adversarial\\nexamples. In ICML , 2019.\\n[10] Pin-Yu Chen, Yash Sharma, Huan Zhang, Jinfeng Yi, and Cho-Jui Hsieh. Ead: elastic-net attacks to deep\\nneural networks via adversarial examples. In Thirty-second AAAI conference on artiﬁcial intelligence ,\\n2018.\\n[11] Pin-Yu Chen, Huan Zhang, Yash Sharma, Jinfeng Yi, and Cho-Jui Hsieh. Zoo: Zeroth order optimization\\nbased black-box attacks to deep neural networks without training substitute models. In Proceedings of the\\n10th ACM Workshop on Artiﬁcial Intelligence and Security , pages 15–26. ACM, 2017.\\n[12] Tianqi Chen and Carlos Guestrin. XGBoost: A scalable tree boosting system. In Proceedings of the 22nd\\nacm sigkdd international conference on knowledge discovery and data mining , pages 785–794. ACM,\\n2016.\\n[13] Minhao Cheng, Thong Le, Pin-Yu Chen, Jinfeng Yi, Huan Zhang, and Cho-Jui Hsieh. Query-efﬁcient\\nhard-label black-box attack: An optimization-based approach. In ICLR , 2019.\\n[14] Gil Einziger, Maayan Goldstein, Yaniv Sa’ar, and Itai Segall. Verifying robustness of gradient boosted\\nmodels. In AAAI , 2019.\\n[15] Kevin Eykholt, Ivan Evtimov, Earlence Fernandes, Bo Li, Amir Rahmati, Chaowei Xiao, Atul Prakash,\\nTadayoshi Kohno, and Dawn Song. Robust physical-world attacks on deep learning models. arXiv preprint\\narXiv:1707.08945 , 2017.\\n[16] Timon Gehr, Matthew Mirman, Dana Drachsler-Cohen, Petar Tsankov, Swarat Chaudhuri, and Martin\\nVechev. Ai2: Safety and robustness certiﬁcation of neural networks with abstract interpretation. In 2018\\nIEEE Symposium on Security and Privacy (SP) , pages 3–18. IEEE, 2018.\\n[17] Ian Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples.\\nInInternational Conference on Learning Representations , 2015.\\n[18] Andrew Ilyas, Logan Engstrom, Anish Athalye, and Jessy Lin. Black-box adversarial attacks with limited\\nqueries and information. In International Conference on Machine Learning , pages 2142–2151, 2018.\\n[19] Kyle D Julian, Shivam Sharma, Jean-Baptiste Jeannin, and Mykel J Kochenderfer. Verifying aircraft\\ncollision avoidance neural networks through linear approximations of safe regions. arXiv preprint\\narXiv:1903.00762 , 2019.\\n[20] Alex Kantchelian, JD Tygar, and Anthony Joseph. Evasion and hardening of tree ensemble classiﬁers. In\\nInternational Conference on Machine Learning , pages 2387–2396, 2016.\\n10[21] Guy Katz, Clark Barrett, David L Dill, Kyle Julian, and Mykel J Kochenderfer. Reluplex: An efﬁcient smt\\nsolver for verifying deep neural networks. In International Conference on Computer Aided Veriﬁcation ,\\npages 97–117. Springer, 2017.\\n[22] Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan\\nLiu. Lightgbm: A highly efﬁcient gradient boosting decision tree. In Advances in Neural Information\\nProcessing Systems , pages 3146–3154, 2017.\\n[23] Alexey Kurakin, Ian Goodfellow, and Samy Bengio. Adversarial machine learning at scale. arXiv preprint\\narXiv:1611.01236 , 2016.\\n[24] Yanpei Liu, Xinyun Chen, Chang Liu, and Dawn Song. Delving into transferable adversarial examples and\\nblack-box attacks. arXiv preprint arXiv:1611.02770 , 2016.\\n[25] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards\\ndeep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083 , 2017.\\n[26] Mohammad Mirghorbani and P Krokhmal. On ﬁnding k-cliques in k-partite graphs. Optimization Letters ,\\n7(6):1155–1165, 2013.\\n[27] Nicolas Papernot, Patrick McDaniel, and Ian Goodfellow. Transferability in machine learning: from\\nphenomena to black-box attacks using adversarial samples. arXiv preprint arXiv:1605.07277 , 2016.\\n[28] Nicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z Berkay Celik, and Ananthram Swami.\\nPractical black-box attacks against machine learning. In Proceedings of the 2017 ACM on Asia conference\\non computer and communications security , pages 506–519. ACM, 2017.\\n[29] Charles A Phillips, Kai Wang, Erich J Baker, Jason A Bubier, Elissa J Chesler, and Michael A Langston.\\nOn ﬁnding and enumerating maximal and maximum k-partite cliques in k-partite graphs. Algorithms ,\\n12(1):23, 2019.\\n[30] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. Anchors: High-precision model-agnostic\\nexplanations. In Thirty-Second AAAI Conference on Artiﬁcial Intelligence , 2018.\\n[31] Fred S Roberts. On the boxicity and cubicity of a graph. Recent Progresses in Combinatorics , pages\\n301–310, 1969.\\n[32] Hadi Salman, Greg Yang, Huan Zhang, Cho-Jui Hsieh, and Pengchuan Zhang. A convex relaxation barrier\\nto tight robustness veriﬁcation of neural networks. arXiv preprint arXiv:1902.08722 , 2019.\\n[33] Naoto Sato, Hironobu Kuruma, Yuichiroh Nakagawa, and Hideto Ogawa. Formal veriﬁcation of decision-\\ntree ensemble model and detection of its violating-input-value ranges. arXiv preprint arXiv:1904.11753 ,\\n2019.\\n[34] Markus Schneider and Burkhard Wulfhorst. Cliques in k-partite graphs and their application in textile\\nengineering. 2002.\\n[35] Gagandeep Singh, Timon Gehr, Matthew Mirman, Markus Püschel, and Martin Vechev. Fast and effective\\nrobustness certiﬁcation. In Advances in Neural Information Processing Systems , pages 10802–10813,\\n2018.\\n[36] Gagandeep Singh, Timon Gehr, Markus Püschel, and Martin Vechev. An abstract domain for certifying\\nneural networks. Proceedings of the ACM on Programming Languages , 3(POPL):41, 2019.\\n[37] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and\\nRob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199 , 2013.\\n[38] Vincent Tjeng, Kai Xiao, and Russ Tedrake. Evaluating robustness of neural networks with mixed integer\\nprogramming. arXiv preprint arXiv:1711.07356 , 2017.\\n[39] John Törnblom and Simin Nadjm-Tehrani. Formal veriﬁcation of input-output mappings of tree ensembles.\\narXiv preprint arXiv:1905.04194 , 2019.\\n[40] Jonathan Uesato, Brendan O’Donoghue, Aaron van den Oord, and Pushmeet Kohli. Adversarial risk and\\nthe dangers of evaluating against weak attacks. arXiv preprint arXiv:1802.05666 , 2018.\\n[41] Shiqi Wang, Yizheng Chen, Ahmed Abdou, and Suman Jana. Mixtrain: Scalable training of formally\\nrobust neural networks. arXiv preprint arXiv:1811.02625 , 2018.\\n11[42] Tsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Luca Daniel, Duane Boning,\\nand Inderjit Dhillon. Towards fast computation of certiﬁed robustness for relu networks. In International\\nConference on Machine Learning , pages 5273–5282, 2018.\\n[43] Eric Wong and J Zico Kolter. Provable defenses against adversarial examples via the convex outer\\nadversarial polytope. In International Conference on Machine Learning , 2018.\\n[44] Eric Wong, Frank Schmidt, Jan Hendrik Metzen, and J Zico Kolter. Scaling provable adversarial defenses.\\nInAdvances in Neural Information Processing Systems , pages 8400–8409, 2018.\\n[45] Kaidi Xu, Sijia Liu, Pu Zhao, Pin-Yu Chen, Huan Zhang, Quanfu Fan, Deniz Erdogmus, Yanzhi Wang,\\nand Xue Lin. Structured adversarial attack: Towards general implementation and better interpretability.\\nICLR , 2019.\\n[46] Huan Zhang, Si Si, and Cho-Jui Hsieh. GPU-acceleration for large-scale tree boosting. SysML Conference ,\\n2018.\\n[47] Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel. Efﬁcient neural network\\nrobustness certiﬁcation with general activation functions. In Advances in Neural Information Processing\\nSystems , pages 4939–4948, 2018.\\n12A Data Statistics and Model Parameters in Tables 1 and 2\\nTable 3 presents data statistics and parameters for the models in Tables 1 and 2 in the main text. The standard\\ntest accuracy is the model accuracy on natural, unmodiﬁed test sets.\\nDatasettraining test # of # of # of robust depth standard test acc.\\nset size set size features classes trees\\x0frobust natural robust natural\\nbreast-cancer 546 137 10 2 4 0.3 8 6 .978 .964\\ncovtype 400,000 181,000 54 7 80 0.2 8 8 .847 .877\\ndiabetes 614 154 8 2 20 0.2 5 5 .786 .773\\nFashion-MNIST 60,000 10,000 784 10 200 0.1 8 8 .903 .903\\nHIGGS 10,500,000 500,000 28 2 300 0.05 8 8 .709 .760\\nijcnn1 49,990 91,701 22 2 60 0.1 8 8 .959 .980\\nMNIST 60,000 10,000 784 10 200 0.3 8 8 .980 .980\\nwebspam 300,000 50,000 254 2 100 0.05 8 8 .983 .992\\nMNIST 2 vs. 6 11,876 1,990 784 2 1000 0.3 6 4 .997 .998\\nTable 3: The data statistics and parameters for the models presented in Tables 1 and 2.\\nB Results for Solving Single Layer Bounds with Dynamic Programming\\nIn this section we provide results of our algorithm by using Eq. (7)for solving the last single layer bounds. Since\\nusing dynamic programming to ﬁnd the maximum valued path in a graph can take signiﬁcantly longer time\\nthan using (6), we found that the solving time increases noticeably if using the same TandLvalues. For some\\nmodels, we reduce the values of TorLin order to speed up our method with dynamic programming. But even\\nwith smaller TorLvalues, the lower bounds rcan also be improved with dynamic programming.\\nDatasetMILP [20] Ours (with DP) Ours vs. MILP\\navg.r\\x03avg. timeTLavg.rouravg. timerour=r\\x03speedup\\nbreast-cancer .210 .012s 21 .209 .001s 1.00 12X\\ncovtype :028?355?s23 .024 5.70s .86 62X\\ndiabetes .049 .061s 22 .044 .013s .90 4.7X\\nFashion-MNIST :014?1150?s21 .012 22.8s .86 50X\\nHIGGS :0028?68?min 41.0023 22.1s .82 185X\\nijcnn1 .030 4.64s 21 .027 .053s .90 88X\\nMNIST :011?367?s21 .011 5.10s 1.00 72X\\nwebspam .00076 47.2s 21.00051 3.29s .67 14X\\nMNIST 2 vs. 6 .057 23.0s 41 .050 2.41s .88 9.5X\\nTable 4: Average `1distortion over 500 examples and average veriﬁcation time per example for three\\nveriﬁcation methods. Here we evaluate the bounds for standard (natural) GBDT models . Results\\nmarked with a star (“ ?”) are the averages of 50 examples due to long running time. Tis the number\\nof independent sets and Lis the number of levels in searching cliques used in our algorithm. A ratio\\nrour=r\\x03close to 1 indicates better lower bound quality.\\nDatasetMILP [20] Ours (with DP) Ours vs. MILP\\navg.r\\x03avg. timeTLavg.rouravg. timerour=r\\x03speedup\\nbreast-cancer .400 .009s 21 .399 .001s 1.00 9.0X\\ncovtype :046?305?s22 .035 3.69s .76 83X\\ndiabetes .112 .034s 22 .111 .005s .98 7.1X\\nFashion-MNIST :091?41?min 21 .071 19.9s .78 124X\\nHIGGS :0084?59?min 41.0069 4.25s .82 783X\\nijcnn1 .036 2.52s 22 .035 .655s .97 3.8X\\nMNIST :264?615?s21 .264 7.74s 1.00 63X\\nwebspam .015 83.7s 21 .011 1.26s .73 66X\\nMNIST 2 vs. 6 .313 91.5s 21 .309 5.91s .99 15.5X\\nTable 5: Veriﬁcation bounds and running time for robustly trained GBDT models introduced in [ 9].\\nThe settings for each method are similar to the settings in Table 4.\\nC Connection between the Score in Figure 4 and Other Feature Importance\\nScores\\nWe note that our perturbation-sensitivity notion of feature importance is complementary to the conventional\\ntree/forest feature importance, with several critical differences. In Figure 5 below we show the feature importance\\nmap of the same standard and robust models used in Figure 4 in the main text. A feature’s importance is measured\\nby the average gain across all the splits it is used in. Pixels with darker color have larger importance and yellow\\npixels have zero importance. Our single-feature robustness bounds shown in Figure 4 are different from\\nimportance scores (Figure 5) in the following ways:\\n\\x0fThe conventional feature importance score only depends on the model itself, and is test data indepen-\\ndent. Conversely, our single-feature robustness bound depends on both the model and the test data\\npoint; for different data points, the model may be sensitive to different features.\\n13\\x0fThe conventional feature importance is a heuristic score. Our robustness bound can give a formal\\nguarantee that the model output would not change if this single feature is perturbed within a given\\nrange.\\n\\x0fThe conventional feature importance score assigns non-zero importance to more pixels than our\\nmethod does in general.\\nStandard DT\\n Robust DT\\n020004000\\nFigure 5: Feature importance of the same models as in Figure 4 in the main text. Left: standard DT model;\\nRight: robust DT model. Yellow pixels have zero feature importance while darker pixels have larger importance.\\nA feature’s importance is measured by the average gain across all the splits it is used in.\\nD Proof of Lemma 1\\nLemma 1. For boxes B1; : : : ; BK, ifBi\\\\Bj6=;for all i; j2[K], let\\x16B=B1\\\\B2\\\\\\x01\\x01\\x01\\\\ BKbe their\\nintersection. Then \\x16Bwill also be a box and \\x16B6=;.\\nProof. If we have Kone dimensional intervals I1= (l1; r1]; I2= (l2; r2]; : : : ; I T= (lK; rK], we want to\\nprove if every pair of them have nonempty overlap I1\\\\\\x01\\x01\\x01\\\\ IK6=;. This can be proved by the following.\\nWithout loss of generality we assume l1\\x14l2\\x14\\x01\\x01\\x01\\x14 lK. For each k < K ,Ik\\\\IK6=;implies lK< rk.\\nTherefore, (lT;min(r1; r2; : : : ; r K)]will be a nonempty set that is contained in I1; I2; : : : ; I K. Therefore\\nI1\\\\I2\\\\\\x01\\x01\\x01\\\\ IK6=;and it is another interval.\\nThis can be generalized to d-dimensional boxes. Assume we have boxes B1; : : : ; B Ksuch that Bi\\\\Bj6=;for\\nanyiandj. Then for each dimension we can apply the above proof, which implies that B1\\\\B2\\\\\\x01\\x01\\x01\\\\ BK6=;\\nand the intersection will be another box.\\nE An O(n)time algorithm for verifying a decision tree\\nThe robustness of a single tree can be easily veriﬁed by the following O(n)algorithm, which tra-\\nverse the whole tree and computes the bounding boxes for each node in a depth-ﬁrst search fashion.\\nAlgorithm 3: Linear time `1untargeted attack for a decision tree.\\n1Initial p\\x03= 0; `t=\\x001; rt=1;8t= 1; : : : d ;\\n2ComputeRecursive( 0;0);\\n3Function ComputeRecursive( i; p)\\n4 ifiis leaf node then\\n5 ifvi6=y0then\\n6 p\\x03 min(p\\x03; p);\\n7 else\\n/* Checking conditions for the left child */\\n8 s rti;\\n9 rti min(rti;Iti);\\n10 iflti\\x14rtithen\\n11 ifrti< xtithen\\n12 ComputeRecursive( i.left_child, max(p;jxti\\x00rtij))\\n13 else\\n14 ComputeRecursive( i.left_child, p);\\n15 rti s;\\n/* Checking conditions for the right child */\\n16 s lti;\\n17 lti max(lti;Iti);\\n18 iflti\\x14rtithen\\n19 iflti> xtithen\\n20 ComputeRecursive( i.right_child, max(p;jxti\\x00ltij))\\n21 else\\n22 ComputeRecursive( i.right_child, p);\\n23end\\n14'"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdf_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9anYQisPPEN"
      },
      "outputs": [],
      "source": [
        "combined_text = f\"\"\"\n",
        "    Title/Context/Information:\n",
        "    {pdf_text}\n",
        "\n",
        "    Question Generation Prompt:\n",
        "    Generate 20 unique questions based on the provided information\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0icwtTGZZ26",
        "outputId": "898a6c93-e7d2-497d-f5f5-f0c825ac5c03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-docx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(combined_text)"
      ],
      "metadata": {
        "id": "VEPzT2BEsMS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "Fsp6bQKROuZk",
        "outputId": "59ba5bf5-c22e-4d4d-9781-e7be958d26e8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1. What is the main idea behind adversarial demonstration attacks on large language models?\\n\\n\\n2. What is the purpose of using in-context learning (ICL) in natural language processing (NLP) tasks?\\n\\n\\n3. How does the proposed ICL attack method, advICL, differ from traditional text-based adversarial attacks?\\n\\n\\n4. What are the key findings from the experiments conducted using the advICL attack method?\\n\\n\\n5. How does the number of demonstrations used in ICL impact the robustness of the models against adversarial attacks?\\n\\n\\n6. What is the significance of the observed transferability of adversarial demonstrations across different test examples?\\n\\n\\n7. What are some potential applications of the advICL attack method in practical settings?\\n\\n\\n8. How can the results of this study contribute to improving the robustness of ICL against adversarial attacks?\\n\\n\\n9. What are some limitations or potential challenges associated with the advICL attack method?\\n\\n\\n10. What future research directions can be explored to enhance the understanding and mitigation of adversarial attacks on ICL?'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXvidf47OO9d"
      },
      "outputs": [],
      "source": [
        "from docx import Document\n",
        "doc = Document()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDUhHkVMQBmX"
      },
      "outputs": [],
      "source": [
        "doc.add_paragraph(response.text)\n",
        "doc.add_page_break()\n",
        "\n",
        "    # Save the Word document\n",
        "doc.save('question_doc3.docx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwUReS0TMgLC"
      },
      "outputs": [],
      "source": [
        "from docx import Document\n",
        "def add_responses_to_word(text):\n",
        "    doc = Document()\n",
        "    combined_text = f\"\"\"\n",
        "    Title/Context/Information:\n",
        "    {text}\n",
        "\n",
        "    Question Generation Prompt:\n",
        "    Generate 50 unique questions based on the provided information\n",
        "    \"\"\"\n",
        "    # Assuming model.generate_content() generates the responses\n",
        "    response = model.generate_content(combined_text)  # Replace this with the actual response from your model\n",
        "\n",
        "    # Add content to the Word document\n",
        "    doc.add_paragraph(response.text)\n",
        "    doc.add_page_break()\n",
        "\n",
        "    # Save the Word document\n",
        "    doc.save('question_doc1.docx')\n",
        "\n",
        "# Add responses to the Word document\n",
        "add_responses_to_word(pdf_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "xH82tmQeQsoD",
        "outputId": "b6e5c1c4-e88f-4004-9c13-5debaecfd094"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 279 ms, sys: 28.2 ms, total: 307 ms\n",
            "Wall time: 23.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "response = model.generate_content(combined_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "REgLMA2fQw5r",
        "outputId": "e7d1d6dd-f05e-4d51-e671-ff607c1f4fb2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"**Questions:**\\n\\n1. What is the main cause of the water crisis in Bengaluru?\\n2. What are the major sources of water for Bengaluru city?\\n3. What percentage of the city's population has access to piped water supply?\\n4. What is the per capita water availability in Bengaluru?\\n5. What are the challenges with regard to water provision in Bengaluru?\\n6. What is the main reason for the high water loss in Bengaluru?\\n7. What are the strategies for the city's water woes?\\n8. What are the benefits of roof-top rainwater harvesting?\\n9. What are the challenges and constraints in adopting rooftop rainwater harvesting in Bengaluru?\\n10. How can waste water be used to supplement the existing water resources in Bengaluru?\\n11. What are the limitations of using treated wastewater?\\n12. How can the rejuvenation of lakes help improve water availability in Bengaluru?\\n13. What are the challenges associated with lake rejuvenation in Bengaluru?\\n14. What is the proposed solution to augment the city's water supply?\\n15. What are the merits and demerits of diverting west-flowing rivers to Bengaluru?\\n16. What are some ways to improve the water situation in Bengaluru?\\n17. What is the role of public awareness and education in addressing Bengaluru's water crisis?\\n18. How can water conservation efforts be promoted in Bengaluru?\\n19. What are the implications of the water crisis in Bengaluru for the city's future growth and development?\\n20. What are some innovative technologies that can be explored to address Bengaluru's water challenges?\\n\\n**Answers:**\\n\\n1. The main cause of the water crisis in Bengaluru is the increasing demand for water due to population growth, urbanization, and industrialization, coupled with inadequate water resources and mismanagement.\\n\\n\\n2. The major sources of water for Bengaluru city are surface water from Cauvery and Arkavathi Rivers, and groundwater from bore wells.\\n\\n\\n3. Approximately 60% of the city's population has access to piped water supply.\\n\\n\\n4. The per capita water availability in Bengaluru is about 110–120 liters per capita per day (lpcd).\\n\\n\\n5. The challenges with regard to water provision in Bengaluru include: inadequate supply, disparity in services, high levels of water loss, high cost of production compared to recovery, increased ground water use leading to water table decline, water quality reduction, development of water markets, and weak enforcement of water conservation and reuse initiatives.\\n\\n\\n6. The main reason for the high water loss in Bengaluru is unaccounted for water (UFW) or non-revenue water, which includes transmission losses, leakage through pipes, and unauthorized connections.\\n\\n\\n7. The strategies for the city's water woes include: demand management through water conservation and efficiency measures, and supply enhancement through rainwater harvesting, waste water treatment and reuse, and lake rejuvenation.\\n\\n\\n8. The benefits of roof-top rainwater harvesting include: augmentation of water supply at marginal cost, replenishment of groundwater, reduction of pollution and contamination, provision of clean and safe water, reduction of electricity bills, and low capital cost with maximum benefits.\\n\\n\\n9. The challenges and constraints in adopting roof-top rainwater harvesting in Bengaluru include: space restrictions, availability of water from multiple sources, cost involved, need for alterations in the house, cleaning and maintenance, lack of awareness, negative perceptions about the quality of harvested water, and lack of incentives.\\n\\n\\n10. Waste water can be used to supplement the existing water resources in Bengaluru by treating it to acceptable standards and using it for non-potable purposes such as irrigation, industrial cooling, and construction.\\n\\n\\n11. The limitations of using treated wastewater include: high cost of treatment, potential health risks if not properly treated, public resistance to using recycled water, and the need for separate infrastructure for distribution.\\n\\n\\n12. The rejuvenation of lakes can help improve water availability in Bengaluru by increasing storage capacity, preventing breaching of tanks, and reducing flash floods.\\n\\n\\n13. The challenges associated with lake rejuvenation in Bengaluru include: high capital cost, weak enforcement of lake protection regulations, encroachment and pollution of lakes, and the need for coordination among multiple agencies.\\n\\n\\n14. The proposed solution to augment the city's water supply is to divert water from west-flowing rivers, which involves bringing water from a distance in difficult terrains and requires huge investments.\\n\\n\\n15. The merits of diverting west-flowing rivers to Bengaluru include: increased water supply, potential to meet the growing water demand, and reduced reliance on groundwater. The demerits include: high cost of implementation, environmental impacts, and potential conflicts with other regions over water sharing.\\n\\n\\n16. Some ways to improve the water situation in Bengaluru include: promoting judicious use of water, implementing water conservation and efficiency measures, encouraging rainwater harvesting and waste water reuse, rejuvenating lakes and tanks, exploring innovative water technologies, and strengthening water governance and management.\\n\\n\\n17. Public awareness and education play a crucial role in addressing Bengaluru's water crisis by: raising awareness about the severity of the water crisis, promoting water conservation practices, encouraging adoption of rainwater harvesting and waste water reuse, and building a sense of collective responsibility for water management.\\n\\n\\n18. Water conservation efforts in Bengaluru can be promoted through: public awareness campaigns, water pricing reforms to encourage efficient use, mandatory rainwater harvesting and waste water reuse, promoting water-efficient technologies and practices, and strengthening regulations and enforcement mechanisms.\\n\\n\\n19. The implications of the water crisis in Bengaluru for the city's future growth and development include: potential constraints on economic growth due to water scarcity, increased health risks due to poor water quality and sanitation, social tensions and conflicts over water sharing, and damage to the city's reputation and attractiveness as a place to live and work.\\n\\n\\n20. Some innovative technologies that can be explored to address Bengaluru's water challenges include: rainwater harvesting systems that can be integrated into building design, decentralized waste water treatment systems, smart water meters and sensors for real-time monitoring of water usage, and nature-based solutions such as green infrastructure and urban forests for stormwater management and water conservation.\""
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "3xwNH71cRBmi",
        "outputId": "9d0ac39d-9c65-4ccb-d384-0305057fdced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 277 ms, sys: 38.7 ms, total: 316 ms\n",
            "Wall time: 24.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "response1 = model.generate_content(combined_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "W7ZfABKpR2Va",
        "outputId": "30f40842-344f-412d-9402-334fb39d91ff"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"**Question 1:** What is the primary source of water for the city of Bengaluru?\\n**Answer:** The primary sources of water for Bengaluru are the Cauvery River and Arkavathi River.\\n\\n**Question 2:** What percentage of the city's water supply comes from surface water sources?\\n**Answer:** Approximately 60% of Bengaluru's water supply comes from surface water sources.\\n\\n**Question 3:** How much water does BWSSB supply to the city per day?\\n**Answer:** BWSSB supplies approximately 950 MLD (million liters per day) of water to Bengaluru.\\n\\n**Question 4:** What is the estimated water demand for Bengaluru's population?\\n**Answer:** The estimated water demand for Bengaluru's population is around 1342 MLD.\\n\\n**Question 5:** What is the main challenge in providing efficient water distribution in Bengaluru?\\n**Answer:** The inadequate infrastructure and high transmission losses (UFW) are the main challenges in providing efficient water distribution.\\n\\n**Question 6:** What is the average per capita water availability in Bengaluru?\\n**Answer:** The average per capita water availability in Bengaluru is approximately 110-120 liters per capita per day (lpcd).\\n\\n**Question 7:** What is the primary cause of water scarcity in Bengaluru?\\n**Answer:** The primary cause of water scarcity in Bengaluru is the increasing demand due to population growth and urbanization, coupled with inadequate water supply.\\n\\n**Question 8:** How many ground-level reservoirs and overhead tanks does BWSSB have?\\n**Answer:** BWSSB has 55 ground-level reservoirs and 47 overhead tanks to store and distribute water across the city.\\n\\n**Question 9:** What is the estimated unaccounted for water (UFW) in Bengaluru's water distribution system?\\n**Answer:** The estimated UFW in Bengaluru's water distribution system is approximately 50%.\\n\\n**Question 10:** What are the main reasons for high UFW in Bengaluru?\\n**Answer:** The high UFW in Bengaluru is primarily due to transmission losses, leakage through pipes, and unauthorized connections.\\n\\n**Question 11:** What is the cost incurred by BWSSB to provide one kiloliter of water?\\n**Answer:** The cost incurred by BWSSB to provide one kiloliter of water is approximately ₹32.\\n\\n**Question 12:** How much does BWSSB recover from consumers for one kiloliter of water?\\n**Answer:** BWSSB recovers approximately ₹6 for the initial 8000 liters of water consumed, with marginal increases based on consumption.\\n\\n**Question 13:** What is the estimated number of borewell connections in Bengaluru?\\n**Answer:** The estimated number of borewell connections in Bengaluru is approximately 3.2 lakh, of which 7000 are owned by BWSSB.\\n\\n**Question 14:** How much water do borewells contribute to Bengaluru's water supply?\\n**Answer:** Borewells contribute approximately 341 MLD of water to Bengaluru's water supply.\\n\\n**Question 15:** What is the total water supply from surface and ground water sources in Bengaluru?\\n**Answer:** The total water supply from surface and ground water sources in Bengaluru is approximately 1023 MLD.\\n\\n**Question 16:** How many lakes and tanks were there in Bengaluru during the 1960s?\\n**Answer:** During the 1960s, there were approximately 280 lakes and tanks in Bengaluru.\\n\\n**Question 17:** How many lakes and tanks remain in Bengaluru today?\\n**Answer:** Today, only 81 lakes and tanks remain in Bengaluru.\\n\\n**Question 18:** What are the main impacts of the reduction in lakes and tanks in Bengaluru?\\n**Answer:** The reduction in lakes and tanks in Bengaluru has led to depletion of groundwater, flooding, reduction in water storage, and loss of flora and fauna.\\n\\n**Question 19:** What are the main parameters used to assess water quality?\\n**Answer:** The main parameters used to assess water quality are physical, chemical, and biological parameters.\\n\\n**Question 20:** What are the main sources of water pollution in Bengaluru?\\n**Answer:** The main sources of water pollution in Bengaluru include cross-contamination of water supply lines, sewage contamination, and poor personal hygiene.\\n\\n**Question 21:** What is the main strategy adopted by BWSSB to improve water distribution and reduce UFW?\\n**Answer:** BWSSB has adopted various strategies to improve water distribution and reduce UFW, including fixing leaks, replacing old pipes, and installing meters.\\n\\n**Question 22:** What is the potential of rooftop rainwater harvesting in Bengaluru?\\n**Answer:** Rooftop rainwater harvesting has the potential to offset some of the water crisis in Bengaluru, given the city's annual rainfall of 970 mm.\\n\\n**Question 23:** What are the benefits of rooftop rainwater harvesting?\\n**Answer:** Rooftop rainwater harvesting offers benefits such as reduced UFW, groundwater recharge, improved water quality, and lower electricity bills.\\n\\n**Question 24:** What are the challenges in implementing rooftop rainwater harvesting in Bengaluru?\\n**Answer:** The challenges in implementing rooftop rainwater harvesting in Bengaluru include space restrictions, cost of installation, and lack of awareness.\\n\\n**Question 25:** What is the potential of wastewater treatment and reuse in Bengaluru?\\n**Answer:** Wastewater treatment and reuse has the potential to supplement Bengaluru's water supply, as the city generates approximately 720 MLD of wastewater.\\n\\n**Question 26:** What are the benefits of wastewater treatment and reuse?\\n**Answer:** Wastewater treatment and reuse offer benefits such as increased water supply, reduced pollution, and conservation of water resources.\\n\\n**Question 27:** What are the challenges in implementing wastewater treatment and reuse in Bengaluru?\\n**Answer:** The challenges in implementing wastewater treatment and reuse in Bengaluru include high investment costs, need for specialized infrastructure, and public acceptance.\\n\\n**Question 28:** How many lakes have been restored in Bengaluru?\\n**Answer:** As of 2011, 31 lakes have been restored in Bengaluru, with another 24 in the process of being restored.\\n\\n**Question 29:** What are the benefits of lake rejuvenation?\\n**Answer:** Lake rejuvenation provides benefits such as increased storage capacity, flood control, and improved water quality.\\n\\n**Question 30:** What are the challenges in implementing lake rejuvenation in Bengaluru?\\n**Answer:** The challenges in implementing lake rejuvenation in Bengaluru include high costs, regulatory hurdles, and encroachment issues.\\n\\n**Question 31:** What is the estimated cost of diverting west-flowing rivers to augment Bengaluru's water supply?\\n**Answer:** Diverting west-flowing rivers to\""
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response1.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIjMfMMBSXVd"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "\n",
        "def extract_paragraphs_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        num_pages = len(pdf_reader.pages)  # Get the number of pages directly\n",
        "        print(num_pages)\n",
        "        paragraphs = []\n",
        "        for page_num in range(num_pages):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            text = page.extract_text()\n",
        "            # Split text into paragraphs based on a delimiter (e.g., newline)\n",
        "            paragraphs.extend(text.split('\\n\\n'))  # Change the delimiter as needed\n",
        "\n",
        "        return paragraphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HC25bsDXKx_",
        "outputId": "c22d9bd8-431b-44b4-87e7-2bd3fb2cc506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n"
          ]
        }
      ],
      "source": [
        "# Replace 'path_to_your_pdf.pdf' with the path to your PDF file\n",
        "pdf_paragraphs = extract_paragraphs_from_pdf('/content/10-CWRDM-Bengaluru-water.pdf')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOmBGoLHXcX8"
      },
      "outputs": [],
      "source": [
        "from docx import Document\n",
        "for page in pdf_paragraphs:\n",
        "  combined_text = f\"\"\"\n",
        "    Title/Context/Information:\n",
        "    {page}\n",
        "\n",
        "    Question Generation Prompt:\n",
        "    Generate 50 unique question and answer pairs together based on the provided information\n",
        "    \"\"\"\n",
        "  response = model.generate_content(combined_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "aIgQSFljZptK",
        "outputId": "9368cbea-4205-4df8-d4cc-d1eefae0dbad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ],
      "source": [
        "from docx import Document\n",
        "def add_responses_to_word(paragraphs):\n",
        "    doc = Document()\n",
        "    for idx, page in enumerate(paragraphs, start=1):\n",
        "        combined_text = f\"\"\"Task Description: You are a school teacher who has to prepare questions and their answers for students practice\n",
        "                    Generate question and answers based on the provided text. The generated questions and answers should cover various aspects such as factual details, inferences, summaries, and implications derived from the text.Below is an example.\n",
        "\n",
        "                    Example Text:\n",
        "                    \"The discovery of antibiotics revolutionized medicine in the 20th century. Alexander Fleming's accidental discovery of penicillin in 1928 paved the way for the widespread use of antibiotics. These medications have saved countless lives by effectively combating bacterial infections. However, overuse and misuse of antibiotics have led to the development of antibiotic-resistant bacteria, posing a significant challenge to modern medicine.\"\n",
        "\n",
        "                    Generated QA:\n",
        "\n",
        "                    Q:What was the year of Alexander Fleming's accidental discovery of penicillin?\n",
        "                    A: 1928\n",
        "                    Q:How did the discovery of antibiotics impact medical treatment in the 20th century?\n",
        "                    A: The discovery of antibiotics revolutionized medical treatment in the 20th century by introducing a highly effective means of combating bacterial infections. It enabled the successful treatment of previously life-threatening illnesses and significantly reduced mortality rates associated with infections. This breakthrough facilitated the development of various medical procedures, surgeries, and treatments that relied on the ability to control bacterial infections, marking a pivotal advancement in modern medicine.\n",
        "                    Q: What challenges arose due to the overuse and misuse of antibiotics?\n",
        "                    A: The overuse and misuse of antibiotics have led to the emergence of antibiotic-resistant bacteria. This phenomenon poses a significant challenge to modern medicine as these resistant strains render many antibiotics ineffective, making infections harder to treat. It creates a scenario where common infections become potentially life-threatening, requiring alternative treatments and intensifying the search for new antibiotics.\n",
        "                    Q: Can you summarize the significance of antibiotics in modern medicine?\n",
        "                    A: Antibiotics have fundamentally transformed modern medicine by revolutionizing the treatment of bacterial infections. Their discovery and widespread use have saved countless lives, enabling successful management of infections that were once fatal. Antibiotics have facilitated advancements in medical procedures, surgeries, and treatments, allowing for better healthcare outcomes and improving the overall quality of life.\n",
        "\n",
        "                    Context/Information:\n",
        "                    {page}\n",
        "\n",
        "                    Generated QA:\n",
        "                    \"\"\"\n",
        "        # Assuming model.generate_content() generates the responses\n",
        "        response = model.generate_content(combined_text)\n",
        "\n",
        "        # Add content to the Word document\n",
        "        doc.add_paragraph(response.text)\n",
        "\n",
        "    # Save the Word document\n",
        "    doc.save('water_qa_doc.docx')\n",
        "\n",
        "# Replace 'path_to_your_pdf.pdf' with the path to your PDF file\n",
        "pdf_paragraphs = extract_paragraphs_from_pdf('/content/WP 307 - Krishna Raj.pdf')\n",
        "\n",
        "# Add responses to the Word document\n",
        "add_responses_to_word(pdf_paragraphs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gI_uJEHaGoy",
        "outputId": "73afc935-4479-4bb7-d062-eec3cbe45713"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16\n"
          ]
        }
      ],
      "source": [
        "# Replace 'path_to_your_pdf.pdf' with the path to your PDF file\n",
        "pdf_paragraphs = extract_paragraphs_from_pdf('/content/bangaluru_portrait.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Blb1Uquoca1g"
      },
      "outputs": [],
      "source": [
        "doc = Document()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kYcRrzicffK"
      },
      "outputs": [],
      "source": [
        "\n",
        "combined_text = f\"\"\"\n",
        "            You are a school teacher who has to prepare questions for students test from the text given below:\n",
        "\n",
        "            Title/Context/Information:\n",
        "            {pdf_paragraphs[10]}\n",
        "\n",
        "            Question Generation Prompt:\n",
        "            Generate 10 unique question and answer pairs together based on the provided information\n",
        "            \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTByYl29ctHb"
      },
      "outputs": [],
      "source": [
        "response = model.generate_content(combined_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e_fbItSc3cy"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "response = model.generate_content(combined_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1Wtnu7xedpw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "\n",
        "# Replace 'folder_path' with the path to your folder containing PDF documents\n",
        "folder_path = '/content/data'\n",
        "# Loop through files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.pdf'):  # Check for PDF files\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Open the PDF file\n",
        "        with open(file_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            num_pages = len(reader.pages)\n",
        "\n",
        "            text = ''\n",
        "            for page_num in range(num_pages):\n",
        "              page = reader.pages[page_num]\n",
        "              text += page.extract_text()\n",
        "\n",
        "            combined_text = f\"\"\"\n",
        "                        Title/Context/Information:\n",
        "                        {pdf_text}\n",
        "\n",
        "                        Question Generation Prompt:\n",
        "                        Generate 20 unique questions based on the provided information and start question with Q:\n",
        "                        \"\"\"\n",
        "            response = model.generate_content(combined_text)\n",
        "            doc = Document()\n",
        "            doc.add_paragraph(response.text)\n",
        "            custom_name = f\"{filename}_que.docx\"\n",
        "            doc.save(custom_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nXbv03kqHSC"
      },
      "outputs": [],
      "source": [
        "combined_text = f\"\"\"Task Description:Generate 20 questions based on the provided text. The generated questions should cover various aspects such as factual details, inferences, summaries, and implications derived from the text.Below is an example.\n",
        "\n",
        "                    Example Text:\n",
        "                    \"The discovery of antibiotics revolutionized medicine in the 20th century. Alexander Fleming's accidental discovery of penicillin in 1928 paved the way for the widespread use of antibiotics. These medications have saved countless lives by effectively combating bacterial infections. However, overuse and misuse of antibiotics have led to the development of antibiotic-resistant bacteria, posing a significant challenge to modern medicine.\"\n",
        "\n",
        "                    Generated Questions:\n",
        "\n",
        "                    Factual Detail: What was the year of Alexander Fleming's accidental discovery of penicillin?\n",
        "                    Inference: How did the discovery of antibiotics impact medical treatment in the 20th century?\n",
        "                    Implication: What challenges arose due to the overuse and misuse of antibiotics?\n",
        "                    Summary: Can you summarize the significance of antibiotics in modern medicine?\n",
        "\n",
        "                    Context/Information:\n",
        "                    It is an open question how to train neural networks so\n",
        "                    they will be robust to adversarial examples [6]. Defen\u0002sive distillation [5] was recently proposed as an approach\n",
        "                    to make feed-forward neural networks robust against ad\u0002versarial examples.\n",
        "                    In this short paper, we demonstrate that defensive dis\u0002tillation is not effective. We show that, with a slight mod\u0002ification to a standard attack, one can find adversarial ex\u0002amples on defensively distilled networks. We demon\u0002strate the attack on the MNIST [2] digit recognition task.\n",
        "                    Distillation prevents existing techniques from finding\n",
        "                    adversarial examples by increasing the magnitude of the\n",
        "                    inputs to the softmax layer. This makes an unmodified\n",
        "                    attack fail. We show that if we artificially reduce the\n",
        "                    magnitude of the input to the softmax function, and make\n",
        "                    two other minor changes, the attack succeeds. Our attack\n",
        "                    achieves successful targeted misclassification on 96.4%\n",
        "                    of images by changing on average 4.7% of pixels.\n",
        "\n",
        "                    Generated Questions:\n",
        "                    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6cjSBjlW2GU"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    \"What is the main idea of the research paper?\",\n",
        "    \"What are adversarial examples, and how are they created?\"\n",
        "]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7ApBOTylfwF"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        num_pages = len(reader.pages)\n",
        "\n",
        "        text = ''\n",
        "        for page_num in range(num_pages):\n",
        "            page = reader.pages[page_num]\n",
        "            text += page.extract_text()\n",
        "\n",
        "        return text\n",
        "\n",
        "# Replace 'your_pdf_file.pdf' with the path to your PDF file\n",
        "pdf_text = extract_text_from_pdf('/content/Defensive Distillation is Not Robust to Adversarial Examples.pdf')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a27yXfDQmCjh"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"Task Description: Generate an answer to the given question based on the provided text.\n",
        "\n",
        "text:\n",
        "{pdf_text}\n",
        "\n",
        "Question: {questions}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "nlUCqQKVmqdZ",
        "outputId": "7a2c864f-c741-494a-abc0-5b2a296ba881"
      },
      "outputs": [
        {
          "ename": "ReadTimeout",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutError\u001b[0m: timed out",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    846\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/util.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    792\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketTimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             raise ReadTimeoutError(\n\u001b[0m\u001b[1;32m    372\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Read timed out. (read timeout={timeout_value})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPConnectionPool(host='localhost', port=33133): Read timed out. (read timeout=60.0)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-97c33e1a9c60>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                 Answer:\"\"\"\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             )\n\u001b[0;32m--> 349\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_since_first_attempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             response = getattr(self._session, method)(\n\u001b[0m\u001b[1;32m    846\u001b[0m                 \u001b[0;34m\"{host}{uri}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \"\"\"\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTimeoutGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m             response = super(AuthorizedSession, self).request(\n\u001b[0m\u001b[1;32m    550\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mReadTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_InvalidHeader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadTimeout\u001b[0m: HTTPConnectionPool(host='localhost', port=33133): Read timed out. (read timeout=60.0)"
          ]
        }
      ],
      "source": [
        "for question in questions:\n",
        "  prompt = f\"\"\"Task Description: Generate an answer to the given question based on the provided text.\n",
        "\n",
        "                text:\n",
        "                {pdf_text}\n",
        "\n",
        "                Question: {question}\n",
        "\n",
        "                Answer:\"\"\"\n",
        "\n",
        "  answer = model.generate_content(prompt)\n",
        "  print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIxIjatWzluV"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain_experimental langchain_core\n",
        "!pip -q install google-generativeai==0.3.1\n",
        "!pip -q install google-ai-generativelanguage==0.4.0\n",
        "!pip -q install langchain-google-genai\n",
        "!pip -q install \"langchain[docarray]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mx_Afg8jnA0-"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.vectorstores import DocArrayInMemorySearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_xUAq6n0mgt"
      },
      "outputs": [],
      "source": [
        "#@title Setting up the Auth\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDAORu8PH3vgsDFoxZAoj13YY9TBasiffM\"\n",
        "\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "#GOOGLE_API_KEY=userdata.get('gemini')\n",
        "\n",
        "#genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmhJFMIT0KCK"
      },
      "outputs": [],
      "source": [
        "model = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
        "                             temperature=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_ky0plU024kV",
        "outputId": "d9bb6cc5-943a-4039-fea1-39d4c27f986e"
      },
      "outputs": [
        {
          "ename": "GoogleGenerativeAIError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutError\u001b[0m: timed out",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    846\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/util.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    792\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketTimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             raise ReadTimeoutError(\n\u001b[0m\u001b[1;32m    372\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Read timed out. (read timeout={timeout_value})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPConnectionPool(host='localhost', port=34711): Read timed out. (read timeout=60.0)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/embeddings.py\u001b[0m in \u001b[0;36m_embed\u001b[0;34m(self, texts, task_type, title)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             result = genai.embed_content(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/embedding.py\u001b[0m in \u001b[0;36membed_content\u001b[0;34m(model, content, task_type, title, client)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0membedding_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchEmbedContentsRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0membedding_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_embed_contents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0membedding_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mbatch_embed_contents\u001b[0;34m(self, request, model, requests, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m   1094\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m             )\n\u001b[0;32m--> 349\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             response = getattr(self._session, method)(\n\u001b[0m\u001b[1;32m    436\u001b[0m                 \u001b[0;34m\"{host}{uri}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTimeoutGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m             response = super(AuthorizedSession, self).request(\n\u001b[0m\u001b[1;32m    550\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mReadTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_InvalidHeader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadTimeout\u001b[0m: HTTPConnectionPool(host='localhost', port=34711): Read timed out. (read timeout=60.0)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mGoogleGenerativeAIError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-011938d58f49>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleGenerativeAIEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"models/embedding-001\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m vectorstore = DocArrayInMemorySearch.from_texts(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# mini docs for embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpdf_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/docarray/in_memory.py\u001b[0m in \u001b[0;36mfrom_texts\u001b[0;34m(cls, texts, embedding, metadatas, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \"\"\"\n\u001b[1;32m     68\u001b[0m         \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadatas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadatas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/docarray/base.py\u001b[0m in \u001b[0;36madd_texts\u001b[0;34m(self, texts, metadatas, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \"\"\"\n\u001b[1;32m     81\u001b[0m         \u001b[0mids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadatas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmetadatas\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/embeddings.py\u001b[0m in \u001b[0;36membed_documents\u001b[0;34m(self, texts, batch_size)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \"\"\"\n\u001b[1;32m     86\u001b[0m         \u001b[0mtask_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_type\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"retrieval_document\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0membed_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/embeddings.py\u001b[0m in \u001b[0;36m_embed\u001b[0;34m(self, texts, task_type, title)\u001b[0m\n\u001b[1;32m     68\u001b[0m             )\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mGoogleGenerativeAIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error embedding content: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mGoogleGenerativeAIError\u001b[0m: Error embedding content: HTTPConnectionPool(host='localhost', port=34711): Read timed out. (read timeout=60.0)"
          ]
        }
      ],
      "source": [
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n",
        "vectorstore = DocArrayInMemorySearch.from_texts(\n",
        "    # mini docs for embedding\n",
        "    pdf_text,\n",
        "\n",
        "    embedding=embeddings # passing in the embedder model\n",
        ")\n",
        "\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DKil3iN5CI6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOnxIEJHX9WzI58h8OAO+fz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}